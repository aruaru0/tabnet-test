{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBm82WerMGZ94fP7eapGHf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aruaru0/tabnet-test/blob/main/tabnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# インストール"
      ],
      "metadata": {
        "id": "juRLJ1GM099l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z3f0V6-xMmQ",
        "outputId": "ffa537a8-e323-4315-818f-5053f0098037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.23.5)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-tabnet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ライブラリのインポート"
      ],
      "metadata": {
        "id": "CilmnMtX1AZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
        "\n",
        "import torch"
      ],
      "metadata": {
        "id": "5S7VTgYKxsPX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データの作成"
      ],
      "metadata": {
        "id": "q6XUmadK1C11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(n_samples=10000,\n",
        "                           n_features=10,\n",
        "                           n_redundant = 3,\n",
        "                           n_informative = 5,\n",
        "                           n_classes=2,\n",
        "                           random_state=42)"
      ],
      "metadata": {
        "id": "bYmxJ9LpxRKk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(X)\n",
        "df['target'] = y\n",
        "df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "YlbVM5LX141_",
        "outputId": "3ffe30a8-e997-49fa-8927-6ac3e0542024"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6  \\\n",
              "0   0.261758  0.392731 -0.808093 -1.848465  1.222284  1.803318  2.896824   \n",
              "1  -0.114392 -0.748236 -0.634377 -0.288498  1.023028  0.367244  0.051039   \n",
              "2   0.312028 -1.492304 -0.711194  0.173962  1.066032  0.183943 -0.046342   \n",
              "3   0.487602 -0.897590 -0.970713 -1.513267  2.705609  2.617096  2.539888   \n",
              "4   0.901587 -0.144531  1.226887  0.285266  3.836804  3.400022 -0.721368   \n",
              "5  -1.512935  0.839964 -2.394045 -3.220995  0.166090  0.238969  3.056046   \n",
              "6   2.482120 -0.753017 -1.266062  0.515353  2.765119 -0.500146 -1.782607   \n",
              "7  -2.288275 -1.994036 -1.838359 -0.860530  0.123930 -0.651246  0.128080   \n",
              "8   0.343655 -0.929279  0.120875  1.019661  0.090647 -0.577260 -1.235540   \n",
              "9   1.747647  1.073376  2.324566  1.597653  1.902705  1.679127 -2.231188   \n",
              "10 -0.241782  0.472553  0.824130  1.052222 -0.683404 -0.956115 -2.101434   \n",
              "11  1.178550  0.637653  0.677428  0.626807  0.793914  0.273878 -1.034278   \n",
              "12  1.040488  1.064623 -0.510586 -0.184280 -1.380595 -1.606008  0.407443   \n",
              "13  0.727044  0.945739  1.110466  0.733568  1.165849  0.632403 -1.784831   \n",
              "14  0.035663  1.754785 -0.000874 -0.043296  0.514033 -0.922058 -2.335279   \n",
              "15  0.140415  0.476550 -2.093543 -1.052213 -1.922572 -2.793633  0.908698   \n",
              "16 -0.311443  0.906557 -1.273276 -2.400870  2.935482  2.146607  1.471082   \n",
              "17  1.648385  2.456168  0.695926  0.035747  0.905919  0.080702 -1.256040   \n",
              "18 -0.127168  2.254707  0.467355 -1.383135  0.735353  1.515613  1.043420   \n",
              "19  1.228359  3.375560 -0.829454 -1.453112 -1.081948 -1.635979  0.598493   \n",
              "\n",
              "           7         8         9  target  \n",
              "0  -0.346674 -1.214386 -2.812468       0  \n",
              "1   1.270733  0.622655 -0.256778       0  \n",
              "2  -1.260676 -0.278665 -0.392808       0  \n",
              "3   0.348632  0.029463 -3.403255       0  \n",
              "4   1.370580 -0.094590 -2.163323       1  \n",
              "5  -0.654477 -0.908181 -0.925463       0  \n",
              "6  -0.286599  1.539449  0.554886       0  \n",
              "7   0.261330  1.306397  1.081350       0  \n",
              "8   2.338216 -0.026320  0.787484       0  \n",
              "9   0.273718 -1.536220 -0.421791       1  \n",
              "10  1.120874 -0.929886  1.968974       1  \n",
              "11  1.585863  1.066611  0.065491       0  \n",
              "12  0.151098 -0.257108  0.617975       1  \n",
              "13 -0.242143  0.309196  0.494858       1  \n",
              "14  0.380048  1.241189  2.410391       1  \n",
              "15 -0.109457 -1.863486  1.504277       1  \n",
              "16 -0.352264 -0.524620 -1.692719       0  \n",
              "17 -1.636983  2.390878  0.527681       1  \n",
              "18  0.384626  0.095094 -1.129615       1  \n",
              "19 -0.375364 -0.215743  0.989669       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ceb12d8d-3632-4782-950b-b59df5adbc98\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.261758</td>\n",
              "      <td>0.392731</td>\n",
              "      <td>-0.808093</td>\n",
              "      <td>-1.848465</td>\n",
              "      <td>1.222284</td>\n",
              "      <td>1.803318</td>\n",
              "      <td>2.896824</td>\n",
              "      <td>-0.346674</td>\n",
              "      <td>-1.214386</td>\n",
              "      <td>-2.812468</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.114392</td>\n",
              "      <td>-0.748236</td>\n",
              "      <td>-0.634377</td>\n",
              "      <td>-0.288498</td>\n",
              "      <td>1.023028</td>\n",
              "      <td>0.367244</td>\n",
              "      <td>0.051039</td>\n",
              "      <td>1.270733</td>\n",
              "      <td>0.622655</td>\n",
              "      <td>-0.256778</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.312028</td>\n",
              "      <td>-1.492304</td>\n",
              "      <td>-0.711194</td>\n",
              "      <td>0.173962</td>\n",
              "      <td>1.066032</td>\n",
              "      <td>0.183943</td>\n",
              "      <td>-0.046342</td>\n",
              "      <td>-1.260676</td>\n",
              "      <td>-0.278665</td>\n",
              "      <td>-0.392808</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.487602</td>\n",
              "      <td>-0.897590</td>\n",
              "      <td>-0.970713</td>\n",
              "      <td>-1.513267</td>\n",
              "      <td>2.705609</td>\n",
              "      <td>2.617096</td>\n",
              "      <td>2.539888</td>\n",
              "      <td>0.348632</td>\n",
              "      <td>0.029463</td>\n",
              "      <td>-3.403255</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.901587</td>\n",
              "      <td>-0.144531</td>\n",
              "      <td>1.226887</td>\n",
              "      <td>0.285266</td>\n",
              "      <td>3.836804</td>\n",
              "      <td>3.400022</td>\n",
              "      <td>-0.721368</td>\n",
              "      <td>1.370580</td>\n",
              "      <td>-0.094590</td>\n",
              "      <td>-2.163323</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-1.512935</td>\n",
              "      <td>0.839964</td>\n",
              "      <td>-2.394045</td>\n",
              "      <td>-3.220995</td>\n",
              "      <td>0.166090</td>\n",
              "      <td>0.238969</td>\n",
              "      <td>3.056046</td>\n",
              "      <td>-0.654477</td>\n",
              "      <td>-0.908181</td>\n",
              "      <td>-0.925463</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.482120</td>\n",
              "      <td>-0.753017</td>\n",
              "      <td>-1.266062</td>\n",
              "      <td>0.515353</td>\n",
              "      <td>2.765119</td>\n",
              "      <td>-0.500146</td>\n",
              "      <td>-1.782607</td>\n",
              "      <td>-0.286599</td>\n",
              "      <td>1.539449</td>\n",
              "      <td>0.554886</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-2.288275</td>\n",
              "      <td>-1.994036</td>\n",
              "      <td>-1.838359</td>\n",
              "      <td>-0.860530</td>\n",
              "      <td>0.123930</td>\n",
              "      <td>-0.651246</td>\n",
              "      <td>0.128080</td>\n",
              "      <td>0.261330</td>\n",
              "      <td>1.306397</td>\n",
              "      <td>1.081350</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.343655</td>\n",
              "      <td>-0.929279</td>\n",
              "      <td>0.120875</td>\n",
              "      <td>1.019661</td>\n",
              "      <td>0.090647</td>\n",
              "      <td>-0.577260</td>\n",
              "      <td>-1.235540</td>\n",
              "      <td>2.338216</td>\n",
              "      <td>-0.026320</td>\n",
              "      <td>0.787484</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.747647</td>\n",
              "      <td>1.073376</td>\n",
              "      <td>2.324566</td>\n",
              "      <td>1.597653</td>\n",
              "      <td>1.902705</td>\n",
              "      <td>1.679127</td>\n",
              "      <td>-2.231188</td>\n",
              "      <td>0.273718</td>\n",
              "      <td>-1.536220</td>\n",
              "      <td>-0.421791</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.241782</td>\n",
              "      <td>0.472553</td>\n",
              "      <td>0.824130</td>\n",
              "      <td>1.052222</td>\n",
              "      <td>-0.683404</td>\n",
              "      <td>-0.956115</td>\n",
              "      <td>-2.101434</td>\n",
              "      <td>1.120874</td>\n",
              "      <td>-0.929886</td>\n",
              "      <td>1.968974</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.178550</td>\n",
              "      <td>0.637653</td>\n",
              "      <td>0.677428</td>\n",
              "      <td>0.626807</td>\n",
              "      <td>0.793914</td>\n",
              "      <td>0.273878</td>\n",
              "      <td>-1.034278</td>\n",
              "      <td>1.585863</td>\n",
              "      <td>1.066611</td>\n",
              "      <td>0.065491</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.040488</td>\n",
              "      <td>1.064623</td>\n",
              "      <td>-0.510586</td>\n",
              "      <td>-0.184280</td>\n",
              "      <td>-1.380595</td>\n",
              "      <td>-1.606008</td>\n",
              "      <td>0.407443</td>\n",
              "      <td>0.151098</td>\n",
              "      <td>-0.257108</td>\n",
              "      <td>0.617975</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.727044</td>\n",
              "      <td>0.945739</td>\n",
              "      <td>1.110466</td>\n",
              "      <td>0.733568</td>\n",
              "      <td>1.165849</td>\n",
              "      <td>0.632403</td>\n",
              "      <td>-1.784831</td>\n",
              "      <td>-0.242143</td>\n",
              "      <td>0.309196</td>\n",
              "      <td>0.494858</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.035663</td>\n",
              "      <td>1.754785</td>\n",
              "      <td>-0.000874</td>\n",
              "      <td>-0.043296</td>\n",
              "      <td>0.514033</td>\n",
              "      <td>-0.922058</td>\n",
              "      <td>-2.335279</td>\n",
              "      <td>0.380048</td>\n",
              "      <td>1.241189</td>\n",
              "      <td>2.410391</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.140415</td>\n",
              "      <td>0.476550</td>\n",
              "      <td>-2.093543</td>\n",
              "      <td>-1.052213</td>\n",
              "      <td>-1.922572</td>\n",
              "      <td>-2.793633</td>\n",
              "      <td>0.908698</td>\n",
              "      <td>-0.109457</td>\n",
              "      <td>-1.863486</td>\n",
              "      <td>1.504277</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-0.311443</td>\n",
              "      <td>0.906557</td>\n",
              "      <td>-1.273276</td>\n",
              "      <td>-2.400870</td>\n",
              "      <td>2.935482</td>\n",
              "      <td>2.146607</td>\n",
              "      <td>1.471082</td>\n",
              "      <td>-0.352264</td>\n",
              "      <td>-0.524620</td>\n",
              "      <td>-1.692719</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.648385</td>\n",
              "      <td>2.456168</td>\n",
              "      <td>0.695926</td>\n",
              "      <td>0.035747</td>\n",
              "      <td>0.905919</td>\n",
              "      <td>0.080702</td>\n",
              "      <td>-1.256040</td>\n",
              "      <td>-1.636983</td>\n",
              "      <td>2.390878</td>\n",
              "      <td>0.527681</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>-0.127168</td>\n",
              "      <td>2.254707</td>\n",
              "      <td>0.467355</td>\n",
              "      <td>-1.383135</td>\n",
              "      <td>0.735353</td>\n",
              "      <td>1.515613</td>\n",
              "      <td>1.043420</td>\n",
              "      <td>0.384626</td>\n",
              "      <td>0.095094</td>\n",
              "      <td>-1.129615</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.228359</td>\n",
              "      <td>3.375560</td>\n",
              "      <td>-0.829454</td>\n",
              "      <td>-1.453112</td>\n",
              "      <td>-1.081948</td>\n",
              "      <td>-1.635979</td>\n",
              "      <td>0.598493</td>\n",
              "      <td>-0.375364</td>\n",
              "      <td>-0.215743</td>\n",
              "      <td>0.989669</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ceb12d8d-3632-4782-950b-b59df5adbc98')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ceb12d8d-3632-4782-950b-b59df5adbc98 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ceb12d8d-3632-4782-950b-b59df5adbc98');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b0dcdd60-b4ed-4e93-9aee-337c83a5f905\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0dcdd60-b4ed-4e93-9aee-337c83a5f905')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b0dcdd60-b4ed-4e93-9aee-337c83a5f905 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_rate, val_rate, test_rate = 0.7, 0.15, 0.15\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_rate, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=test_rate/(test_rate+val_rate), random_state=42)"
      ],
      "metadata": {
        "id": "kuyHPRezxjAo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train), len(X_valid), len(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh3S1WhAyBL7",
        "outputId": "423805d2-3527-42a6-de57-41276c31088a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, 1500, 1500)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y4Ba3ueHyRm6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TabNetを使って予測"
      ],
      "metadata": {
        "id": "BEHbinvV0om4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 事前学習"
      ],
      "metadata": {
        "id": "-4rAB9Um-10a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unsupervised_model = TabNetPretrainer(\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    mask_type='entmax'\n",
        ")\n",
        "\n",
        "unsupervised_model.fit(\n",
        "    X_train=X_train,\n",
        "    eval_set=[X_valid],\n",
        "    pretraining_ratio=0.8,\n",
        "    max_epochs = 100,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtIY8dS-9usI",
        "outputId": "521f3348-f2d7-487d-8421-51332fe21b65"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.98879 | val_0_unsup_loss_numpy: 1.4636800289154053|  0:00:00s\n",
            "epoch 1  | loss: 1.16293 | val_0_unsup_loss_numpy: 1.066640019416809|  0:00:01s\n",
            "epoch 2  | loss: 1.03527 | val_0_unsup_loss_numpy: 0.9839100241661072|  0:00:01s\n",
            "epoch 3  | loss: 1.00156 | val_0_unsup_loss_numpy: 0.956309974193573|  0:00:01s\n",
            "epoch 4  | loss: 0.9737  | val_0_unsup_loss_numpy: 0.9258900284767151|  0:00:02s\n",
            "epoch 5  | loss: 0.95633 | val_0_unsup_loss_numpy: 0.8822600245475769|  0:00:03s\n",
            "epoch 6  | loss: 0.94677 | val_0_unsup_loss_numpy: 0.8386800289154053|  0:00:03s\n",
            "epoch 7  | loss: 0.9276  | val_0_unsup_loss_numpy: 0.790690004825592|  0:00:05s\n",
            "epoch 8  | loss: 0.91786 | val_0_unsup_loss_numpy: 0.7493000030517578|  0:00:05s\n",
            "epoch 9  | loss: 0.89104 | val_0_unsup_loss_numpy: 0.7110599875450134|  0:00:06s\n",
            "epoch 10 | loss: 0.89177 | val_0_unsup_loss_numpy: 0.6906800270080566|  0:00:07s\n",
            "epoch 11 | loss: 0.86912 | val_0_unsup_loss_numpy: 0.6548200249671936|  0:00:08s\n",
            "epoch 12 | loss: 0.87086 | val_0_unsup_loss_numpy: 0.6175500154495239|  0:00:09s\n",
            "epoch 13 | loss: 0.86156 | val_0_unsup_loss_numpy: 0.6071400046348572|  0:00:10s\n",
            "epoch 14 | loss: 0.86038 | val_0_unsup_loss_numpy: 0.5909199714660645|  0:00:12s\n",
            "epoch 15 | loss: 0.85907 | val_0_unsup_loss_numpy: 0.5802599787712097|  0:00:13s\n",
            "epoch 16 | loss: 0.8522  | val_0_unsup_loss_numpy: 0.571370005607605|  0:00:14s\n",
            "epoch 17 | loss: 0.85295 | val_0_unsup_loss_numpy: 0.5581700205802917|  0:00:15s\n",
            "epoch 18 | loss: 0.83908 | val_0_unsup_loss_numpy: 0.5580400228500366|  0:00:15s\n",
            "epoch 19 | loss: 0.84881 | val_0_unsup_loss_numpy: 0.5419099926948547|  0:00:16s\n",
            "epoch 20 | loss: 0.84529 | val_0_unsup_loss_numpy: 0.5326099991798401|  0:00:17s\n",
            "epoch 21 | loss: 0.84395 | val_0_unsup_loss_numpy: 0.5333300232887268|  0:00:18s\n",
            "epoch 22 | loss: 0.84335 | val_0_unsup_loss_numpy: 0.5300899744033813|  0:00:19s\n",
            "epoch 23 | loss: 0.83898 | val_0_unsup_loss_numpy: 0.5230100154876709|  0:00:20s\n",
            "epoch 24 | loss: 0.83545 | val_0_unsup_loss_numpy: 0.5143100023269653|  0:00:21s\n",
            "epoch 25 | loss: 0.82755 | val_0_unsup_loss_numpy: 0.5024200081825256|  0:00:22s\n",
            "epoch 26 | loss: 0.83268 | val_0_unsup_loss_numpy: 0.5072000026702881|  0:00:24s\n",
            "epoch 27 | loss: 0.82742 | val_0_unsup_loss_numpy: 0.5056700110435486|  0:00:26s\n",
            "epoch 28 | loss: 0.82581 | val_0_unsup_loss_numpy: 0.49842000007629395|  0:00:27s\n",
            "epoch 29 | loss: 0.82533 | val_0_unsup_loss_numpy: 0.4977000057697296|  0:00:28s\n",
            "epoch 30 | loss: 0.82537 | val_0_unsup_loss_numpy: 0.48539999127388|  0:00:29s\n",
            "epoch 31 | loss: 0.83068 | val_0_unsup_loss_numpy: 0.49035000801086426|  0:00:30s\n",
            "epoch 32 | loss: 0.83292 | val_0_unsup_loss_numpy: 0.4870400130748749|  0:00:31s\n",
            "epoch 33 | loss: 0.82438 | val_0_unsup_loss_numpy: 0.4826900064945221|  0:00:32s\n",
            "epoch 34 | loss: 0.82884 | val_0_unsup_loss_numpy: 0.48144999146461487|  0:00:33s\n",
            "epoch 35 | loss: 0.82123 | val_0_unsup_loss_numpy: 0.48377999663352966|  0:00:34s\n",
            "epoch 36 | loss: 0.82425 | val_0_unsup_loss_numpy: 0.4841800034046173|  0:00:35s\n",
            "epoch 37 | loss: 0.82643 | val_0_unsup_loss_numpy: 0.4779199957847595|  0:00:36s\n",
            "epoch 38 | loss: 0.82577 | val_0_unsup_loss_numpy: 0.47846001386642456|  0:00:37s\n",
            "epoch 39 | loss: 0.82295 | val_0_unsup_loss_numpy: 0.48385000228881836|  0:00:37s\n",
            "epoch 40 | loss: 0.83345 | val_0_unsup_loss_numpy: 0.4669399857521057|  0:00:38s\n",
            "epoch 41 | loss: 0.8192  | val_0_unsup_loss_numpy: 0.4779900014400482|  0:00:38s\n",
            "epoch 42 | loss: 0.82324 | val_0_unsup_loss_numpy: 0.47558000683784485|  0:00:39s\n",
            "epoch 43 | loss: 0.82071 | val_0_unsup_loss_numpy: 0.46794000267982483|  0:00:39s\n",
            "epoch 44 | loss: 0.82999 | val_0_unsup_loss_numpy: 0.46838998794555664|  0:00:40s\n",
            "epoch 45 | loss: 0.81543 | val_0_unsup_loss_numpy: 0.4736500084400177|  0:00:40s\n",
            "epoch 46 | loss: 0.82367 | val_0_unsup_loss_numpy: 0.4590499997138977|  0:00:41s\n",
            "epoch 47 | loss: 0.83086 | val_0_unsup_loss_numpy: 0.46476998925209045|  0:00:41s\n",
            "epoch 48 | loss: 0.83052 | val_0_unsup_loss_numpy: 0.46086999773979187|  0:00:41s\n",
            "epoch 49 | loss: 0.81393 | val_0_unsup_loss_numpy: 0.4659000039100647|  0:00:42s\n",
            "epoch 50 | loss: 0.80606 | val_0_unsup_loss_numpy: 0.45875000953674316|  0:00:42s\n",
            "epoch 51 | loss: 0.8243  | val_0_unsup_loss_numpy: 0.4601700007915497|  0:00:43s\n",
            "epoch 52 | loss: 0.80939 | val_0_unsup_loss_numpy: 0.4498499929904938|  0:00:43s\n",
            "epoch 53 | loss: 0.81588 | val_0_unsup_loss_numpy: 0.4531500041484833|  0:00:43s\n",
            "epoch 54 | loss: 0.81002 | val_0_unsup_loss_numpy: 0.45805999636650085|  0:00:44s\n",
            "epoch 55 | loss: 0.81011 | val_0_unsup_loss_numpy: 0.45816001296043396|  0:00:44s\n",
            "epoch 56 | loss: 0.81096 | val_0_unsup_loss_numpy: 0.4649699926376343|  0:00:45s\n",
            "epoch 57 | loss: 0.82349 | val_0_unsup_loss_numpy: 0.45809999108314514|  0:00:45s\n",
            "epoch 58 | loss: 0.81266 | val_0_unsup_loss_numpy: 0.45048999786376953|  0:00:45s\n",
            "epoch 59 | loss: 0.81033 | val_0_unsup_loss_numpy: 0.45138999819755554|  0:00:46s\n",
            "epoch 60 | loss: 0.81077 | val_0_unsup_loss_numpy: 0.45006999373435974|  0:00:46s\n",
            "epoch 61 | loss: 0.81799 | val_0_unsup_loss_numpy: 0.4457100033760071|  0:00:47s\n",
            "epoch 62 | loss: 0.82433 | val_0_unsup_loss_numpy: 0.4547399878501892|  0:00:47s\n",
            "epoch 63 | loss: 0.81046 | val_0_unsup_loss_numpy: 0.4549199938774109|  0:00:47s\n",
            "epoch 64 | loss: 0.81385 | val_0_unsup_loss_numpy: 0.45006999373435974|  0:00:48s\n",
            "epoch 65 | loss: 0.81685 | val_0_unsup_loss_numpy: 0.44444000720977783|  0:00:48s\n",
            "epoch 66 | loss: 0.80163 | val_0_unsup_loss_numpy: 0.4487000107765198|  0:00:49s\n",
            "epoch 67 | loss: 0.82069 | val_0_unsup_loss_numpy: 0.44126999378204346|  0:00:50s\n",
            "epoch 68 | loss: 0.81297 | val_0_unsup_loss_numpy: 0.44277000427246094|  0:00:50s\n",
            "epoch 69 | loss: 0.81255 | val_0_unsup_loss_numpy: 0.44183000922203064|  0:00:51s\n",
            "epoch 70 | loss: 0.80943 | val_0_unsup_loss_numpy: 0.4419800043106079|  0:00:51s\n",
            "epoch 71 | loss: 0.80908 | val_0_unsup_loss_numpy: 0.4437899887561798|  0:00:52s\n",
            "epoch 72 | loss: 0.82351 | val_0_unsup_loss_numpy: 0.4496600031852722|  0:00:52s\n",
            "epoch 73 | loss: 0.80736 | val_0_unsup_loss_numpy: 0.44940000772476196|  0:00:52s\n",
            "epoch 74 | loss: 0.81666 | val_0_unsup_loss_numpy: 0.4451099932193756|  0:00:53s\n",
            "epoch 75 | loss: 0.81543 | val_0_unsup_loss_numpy: 0.44078999757766724|  0:00:53s\n",
            "epoch 76 | loss: 0.81112 | val_0_unsup_loss_numpy: 0.4472300112247467|  0:00:54s\n",
            "epoch 77 | loss: 0.81188 | val_0_unsup_loss_numpy: 0.45058000087738037|  0:00:54s\n",
            "epoch 78 | loss: 0.81196 | val_0_unsup_loss_numpy: 0.4437499940395355|  0:00:55s\n",
            "epoch 79 | loss: 0.81039 | val_0_unsup_loss_numpy: 0.44093000888824463|  0:00:55s\n",
            "epoch 80 | loss: 0.81401 | val_0_unsup_loss_numpy: 0.4481799900531769|  0:00:55s\n",
            "epoch 81 | loss: 0.81695 | val_0_unsup_loss_numpy: 0.4299600124359131|  0:00:56s\n",
            "epoch 82 | loss: 0.80948 | val_0_unsup_loss_numpy: 0.4426400065422058|  0:00:56s\n",
            "epoch 83 | loss: 0.81476 | val_0_unsup_loss_numpy: 0.4400399923324585|  0:00:57s\n",
            "epoch 84 | loss: 0.8044  | val_0_unsup_loss_numpy: 0.4340200126171112|  0:00:57s\n",
            "epoch 85 | loss: 0.81229 | val_0_unsup_loss_numpy: 0.4379599988460541|  0:00:57s\n",
            "epoch 86 | loss: 0.80759 | val_0_unsup_loss_numpy: 0.43334999680519104|  0:00:58s\n",
            "epoch 87 | loss: 0.80636 | val_0_unsup_loss_numpy: 0.4361400008201599|  0:00:58s\n",
            "epoch 88 | loss: 0.80761 | val_0_unsup_loss_numpy: 0.43779000639915466|  0:00:59s\n",
            "epoch 89 | loss: 0.81664 | val_0_unsup_loss_numpy: 0.4300299882888794|  0:00:59s\n",
            "epoch 90 | loss: 0.8092  | val_0_unsup_loss_numpy: 0.4290499985218048|  0:00:59s\n",
            "epoch 91 | loss: 0.81684 | val_0_unsup_loss_numpy: 0.4352000057697296|  0:01:00s\n",
            "epoch 92 | loss: 0.80849 | val_0_unsup_loss_numpy: 0.4324299991130829|  0:01:00s\n",
            "epoch 93 | loss: 0.80862 | val_0_unsup_loss_numpy: 0.43303000926971436|  0:01:01s\n",
            "epoch 94 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.4381299912929535|  0:01:01s\n",
            "epoch 95 | loss: 0.81154 | val_0_unsup_loss_numpy: 0.43083998560905457|  0:01:02s\n",
            "epoch 96 | loss: 0.80652 | val_0_unsup_loss_numpy: 0.43999001383781433|  0:01:03s\n",
            "epoch 97 | loss: 0.80528 | val_0_unsup_loss_numpy: 0.42949000000953674|  0:01:03s\n",
            "epoch 98 | loss: 0.8033  | val_0_unsup_loss_numpy: 0.429639995098114|  0:01:04s\n",
            "epoch 99 | loss: 0.81231 | val_0_unsup_loss_numpy: 0.4291599988937378|  0:01:04s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 90 and best_val_0_unsup_loss_numpy = 0.4290499985218048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習"
      ],
      "metadata": {
        "id": "2hG14GTa0lNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tabnet_params = {\n",
        "                 \"optimizer_fn\":torch.optim.Adam,\n",
        "                 \"optimizer_params\":dict(lr=2e-2),\n",
        "                 \"scheduler_params\":{\"step_size\":50, # how to use learning rate scheduler\n",
        "                                 \"gamma\":0.9},\n",
        "                 \"scheduler_fn\":torch.optim.lr_scheduler.StepLR,\n",
        "                 \"mask_type\":'entmax',\n",
        "                 }\n",
        "\n",
        "clf = TabNetClassifier(**tabnet_params\n",
        "                      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AngHxLYkysyj",
        "outputId": "d2fbe9fb-971e-4bd2-f9bd-502baf1c47a4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 20"
      ],
      "metadata": {
        "id": "ZQzUO5NGyxBQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pytorch_tabnet.augmentations import ClassificationSMOTE\n",
        "# aug = ClassificationSMOTE(p=0.2)"
      ],
      "metadata": {
        "id": "VI2z7_d7zL6u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "    eval_name=['train', 'valid'],\n",
        "    eval_metric=['auc'],\n",
        "    max_epochs=max_epochs , patience=20,\n",
        "    batch_size=1024, virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    weights=1,\n",
        "    drop_last=False,\n",
        "    augmentations=None,\n",
        "    from_unsupervised=unsupervised_model\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjHM1K0xy-ET",
        "outputId": "cf4f642f-eccb-4003-ba52-d920acc1f53a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
            "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.63144 | train_auc: 0.82318 | valid_auc: 0.82092 |  0:00:00s\n",
            "epoch 1  | loss: 0.38146 | train_auc: 0.88355 | valid_auc: 0.88751 |  0:00:01s\n",
            "epoch 2  | loss: 0.26928 | train_auc: 0.9151  | valid_auc: 0.91281 |  0:00:01s\n",
            "epoch 3  | loss: 0.24347 | train_auc: 0.93506 | valid_auc: 0.92801 |  0:00:02s\n",
            "epoch 4  | loss: 0.19932 | train_auc: 0.95881 | valid_auc: 0.95796 |  0:00:02s\n",
            "epoch 5  | loss: 0.19286 | train_auc: 0.95787 | valid_auc: 0.953   |  0:00:03s\n",
            "epoch 6  | loss: 0.17665 | train_auc: 0.96217 | valid_auc: 0.96149 |  0:00:03s\n",
            "epoch 7  | loss: 0.1759  | train_auc: 0.97506 | valid_auc: 0.97294 |  0:00:04s\n",
            "epoch 8  | loss: 0.16788 | train_auc: 0.97338 | valid_auc: 0.97047 |  0:00:04s\n",
            "epoch 9  | loss: 0.15998 | train_auc: 0.97976 | valid_auc: 0.97753 |  0:00:05s\n",
            "epoch 10 | loss: 0.15735 | train_auc: 0.97699 | valid_auc: 0.97356 |  0:00:05s\n",
            "epoch 11 | loss: 0.15171 | train_auc: 0.98259 | valid_auc: 0.97899 |  0:00:06s\n",
            "epoch 12 | loss: 0.14816 | train_auc: 0.97924 | valid_auc: 0.97666 |  0:00:07s\n",
            "epoch 13 | loss: 0.1461  | train_auc: 0.98699 | valid_auc: 0.98234 |  0:00:07s\n",
            "epoch 14 | loss: 0.14025 | train_auc: 0.98679 | valid_auc: 0.98173 |  0:00:08s\n",
            "epoch 15 | loss: 0.14536 | train_auc: 0.98605 | valid_auc: 0.98154 |  0:00:08s\n",
            "epoch 16 | loss: 0.14768 | train_auc: 0.98603 | valid_auc: 0.98144 |  0:00:09s\n",
            "epoch 17 | loss: 0.14672 | train_auc: 0.9878  | valid_auc: 0.98314 |  0:00:10s\n",
            "epoch 18 | loss: 0.14678 | train_auc: 0.98867 | valid_auc: 0.98518 |  0:00:11s\n",
            "epoch 19 | loss: 0.14477 | train_auc: 0.98862 | valid_auc: 0.98479 |  0:00:11s\n",
            "Stop training because you reached max_epochs = 20 with best_epoch = 18 and best_valid_auc = 0.98518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bSzDS2Z5zH2E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 予測"
      ],
      "metadata": {
        "id": "WJ8TKvMk0tMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = clf.predict_proba(X_test)\n",
        "test_auc = roc_auc_score(y_score=preds[:,1], y_true=y_test)\n",
        "\n",
        "\n",
        "preds_valid = clf.predict_proba(X_valid)\n",
        "valid_auc = roc_auc_score(y_score=preds_valid[:,1], y_true=y_valid)\n",
        "\n",
        "print(\"valid_auc = \", valid_auc)\n",
        "print(\"test_auc = \", test_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8Akp_RWzUMg",
        "outputId": "5c7d5101-3246-4491-90d7-603917aeaa70"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid_auc =  0.9851784018450686\n",
            "test_auc =  0.9864709407043504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importance = sorted([(i, n) for i, n in enumerate(clf.feature_importances_)], key = lambda x: x[1], reverse = True)\n",
        "label, y = [], []\n",
        "for e in importance:\n",
        "  print(f\"feature {e[0]} : {e[1]}\")\n",
        "  label.append(e[0])\n",
        "  y.append(e[1])\n",
        "\n",
        "plt.bar([i for i in range(len(y))], y, tick_label = label)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "Q4gguBLB1R20",
        "outputId": "3a050159-3070-492e-a55e-cc2066c66ddf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature 9 : 0.2850628122941535\n",
            "feature 5 : 0.16348304202670996\n",
            "feature 0 : 0.14779516687246716\n",
            "feature 3 : 0.1265401265637643\n",
            "feature 2 : 0.07739413530142895\n",
            "feature 6 : 0.0680603533275236\n",
            "feature 1 : 0.06336122861362507\n",
            "feature 4 : 0.043713949430405824\n",
            "feature 8 : 0.023770800553614642\n",
            "feature 7 : 0.00081838501630697\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBMを使って予測"
      ],
      "metadata": {
        "id": "Lqs23c9E0KXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習"
      ],
      "metadata": {
        "id": "zG--1eTm0vO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgb_params = {\n",
        "  'n_estimators': 10000,\n",
        "  'learning_rate': 0.05,\n",
        "  'random_state': 42,\n",
        "  'early_stopping_round': 20,\n",
        "  'metric': 'auc'\n",
        "}\n",
        "\n",
        "lgb = LGBMClassifier(**lgb_params)\n",
        "lgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "kngZ9zF3zaJL",
        "outputId": "9deead3d-ba5b-454e-cdd9-a0e50d9ab356"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 3447, number of negative: 3553\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000926 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2550\n",
            "[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492429 -> initscore=-0.030288\n",
            "[LightGBM] [Info] Start training from score -0.030288\n",
            "Training until validation scores don't improve for 20 rounds\n",
            "Early stopping, best iteration is:\n",
            "[264]\tvalid_0's auc: 0.983045\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(early_stopping_round=20, learning_rate=0.05, metric='auc',\n",
              "               n_estimators=10000, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(early_stopping_round=20, learning_rate=0.05, metric=&#x27;auc&#x27;,\n",
              "               n_estimators=10000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(early_stopping_round=20, learning_rate=0.05, metric=&#x27;auc&#x27;,\n",
              "               n_estimators=10000, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 予測"
      ],
      "metadata": {
        "id": "rkKCzWE50yq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = lgb.predict_proba(X_test)\n",
        "test_auc = roc_auc_score(y_score=preds[:,1], y_true=y_test)\n",
        "\n",
        "\n",
        "preds_valid = lgb.predict_proba(X_valid)\n",
        "valid_auc = roc_auc_score(y_score=preds_valid[:,1], y_true=y_valid)\n",
        "\n",
        "print(\"valid_auc = \", valid_auc)\n",
        "print(\"test_auc = \", test_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA50WlnCz-ZA",
        "outputId": "6a65c6df-7597-44c0-c7e0-890531c9ff51"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid_auc =  0.9830452198873252\n",
            "test_auc =  0.9846662363824835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importance = sorted([(i, n) for i, n in enumerate(lgb.feature_importances_)], key = lambda x: x[1], reverse = True)\n",
        "label, y = [], []\n",
        "for e in importance:\n",
        "  print(f\"feature {e[0]} : {e[1]}\")\n",
        "  label.append(e[0])\n",
        "  y.append(e[1])\n",
        "\n",
        "plt.bar([i for i in range(len(y))], y, tick_label = label)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "q0RDwgiX0HyL",
        "outputId": "14a6f633-1898-4539-fb47-51e4ab6e30d9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature 0 : 1258\n",
            "feature 1 : 1249\n",
            "feature 4 : 1061\n",
            "feature 6 : 946\n",
            "feature 2 : 859\n",
            "feature 5 : 610\n",
            "feature 3 : 582\n",
            "feature 9 : 488\n",
            "feature 8 : 478\n",
            "feature 7 : 389\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XHQ6UvoQDdC5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}